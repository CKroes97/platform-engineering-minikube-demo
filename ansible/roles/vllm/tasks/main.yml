---
- name: Set up envirionment for llama-cpp
  ansible.builtin.include_tasks: setup_environment.yml

- name: Install llama-cpp
  ansible.builtin.include_tasks: llama_cpp.yml
  vars:
    service_user: "vllm"
    vllm_venv_path: "/home/{{ service_user }}/vllm_venv"

- name: Run vllm server
  ansible.builtin.include_tasks: llama-server.yml
  vars:
    vllm_venv_path: "/home/{{ service_user }}/vllm_venv"
    model_dir: "/opt/llama_models"
    model_spec: "ggml-org/gpt-oss-20b-GGUF"
    service_user: "vllm"
    service_name: "vllm"
    service_port: 39443
    threads: 8
    gpu_layers: 20
    ctx_size: 4096
